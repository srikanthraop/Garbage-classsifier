# -*- coding: utf-8 -*-
"""200L3REVIEW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OopvL3now9nrVuWUOOkQ178-dhG4LHeG
"""

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(48, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.applications import InceptionV3,VGG19, ResNet50
# from tensorflow.keras.applications import VGG19
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D, MaxPooling2D,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential,load_model
import numpy as np

train_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.2,horizontal_flip=True, vertical_flip=True)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/DDD/Garbage classification/',
                                                 target_size = (100, 100),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'training')
validation_set = train_datagen.flow_from_directory('/content/drive/MyDrive/DDD/Garbage classification/',
                                                 target_size = (100, 100),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'validation')

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

h=model.fit(training_set, validation_data=validation_set, epochs=200)

import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(
                    y=h.history['accuracy'],
                    name='Train'))
fig.add_trace(go.Scatter(
                    y=h.history['val_accuracy'],
                    name='Valid'))
fig.update_layout(height=500, 
                  width=700,
                  title='Accuracy',
                  xaxis_title='Epoch',
                  yaxis_title='Accuracy')
fig.show()

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(48, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

h=model.fit(training_set, validation_data=validation_set, epochs=50)

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(48, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

h=model.fit(training_set, validation_data=validation_set, epochs=50)

model = Sequential()
model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

h=model.fit(training_set, validation_data=validation_set, epochs=50)

"""NEW DATASET

"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.applications import InceptionV3,VGG19, ResNet50
# from tensorflow.keras.applications import VGG19
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D, MaxPooling2D,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential,load_model
import numpy as np
import matplotlib.pyplot as plt

train_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.2,horizontal_flip=True, vertical_flip=True)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ULTRA DATA/',
                                                 target_size = (100, 100),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'training')
validation_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ULTRA DATA/',
                                                 target_size = (100, 100),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'validation')

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.1))
model.add(Flatten())
model.add(Dense(80, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics=['accuracy'])

his3 =model.fit(training_set, validation_data=validation_set, epochs=50)

"""# GGG dataset

"""

