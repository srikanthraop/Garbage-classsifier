# -*- coding: utf-8 -*-
"""VGG19-final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18A7PSHGEODdgRBFeW82Jo4xCr3Fll_Aa
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.applications import InceptionV3,VGG19, ResNet50
# from tensorflow.keras.applications import VGG19
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D, MaxPooling2D,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential,load_model
import numpy as np
import matplotlib.pyplot as plt

train_path='/content/drive/MyDrive/GGG'
val_path='/content/drive/MyDrive/GGG'

train_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    validation_split=0.2).flow_from_directory(
    directory=train_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='training')
    
valid_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    validation_split=0.2).flow_from_directory(
    directory=val_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='validation')

image_size = [224,224]
vgg = VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)

for l in vgg.layers:
  l.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(4,activation='softmax')(x)
model = Model(inputs=vgg.input, outputs=prediction)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

his=model.fit(train_batches, validation_data=valid_batches, epochs=20)

train_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
   rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    validation_split=0.2).flow_from_directory(
    directory=train_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='training')
    
valid_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    validation_split=0.2).flow_from_directory(
    directory=val_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='validation')



image_size = [224,224]
vgg = VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)

for l in vgg.layers:
  l.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(4,activation='softmax')(x)
model = Model(inputs=vgg.input, outputs=prediction)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

his=model.fit(train_batches, validation_data=valid_batches, epochs=20)

train_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    rotation_range=20,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    validation_split=0.2).flow_from_directory(
    directory=train_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='training')
    
valid_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    validation_split=0.2).flow_from_directory(
    directory=val_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='validation')

image_size = [224,224]
vgg = VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)

for l in vgg.layers:
  l.trainable = False

x = Flatten()(vgg.output)
x = GlobalAveragePooling2D(name='avg_pool')(x)
x = Dropout(0.3)(x)
prediction = Dense(4,activation='softmax')(x)
model = Model(inputs=vgg.input, outputs=prediction)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

train_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.2,horizontal_flip=True, vertical_flip=True)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/GGG/',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'training')
validation_set = train_datagen.flow_from_directory('/content/drive/MyDrive/GGG/',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 subset = 'validation')

image_size = [224,224]
vgg = VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)

for l in vgg.layers:
  l.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(4,activation='softmax')(x)
model = Model(inputs=vgg.input, outputs=prediction)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

his3=model.fit(training_set, validation_data=validation_set, epochs=30)

import matplotlib.pyplot as plt
plt.plot(his3.history['accuracy'])
plt.plot(his3.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(
                    y=his3.history['accuracy'],
                    name='Train'))
fig.add_trace(go.Scatter(
                    y=his3.history['val_accuracy'],
                    name='Valid'))
fig.update_layout(height=500, 
                  width=700,
                  title='Accuracy',
                  xaxis_title='Epoch',
                  yaxis_title='Accuracy')
fig.show()

train_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    rotation_range=20,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    validation_split=0.2).flow_from_directory(
    directory=train_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='training')
    
valid_batches = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,
    validation_split=0.2).flow_from_directory(
    directory=val_path, target_size=(224,224), classes=['cardboard', 'metal', 
                                                         'paper', 'plastic'], batch_size=32, subset='validation')

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/GGG/',
                                                 target_size = (224, 224),
                                                 batch_size = 128,
                                                 class_mode = 'categorical',
                                                 subset = 'training')
validation_set = train_datagen.flow_from_directory('/content/drive/MyDrive/GGG/',
                                                 target_size = (224, 224),
                                                 batch_size = 128,
                                                 class_mode = 'categorical',
                                                 subset = 'validation')



image_size = [224,224]
vgg = VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)

for l in vgg.layers:
  l.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(4,activation='softmax')(x)
model = Model(inputs=vgg.input, outputs=prediction)

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

his4=model.fit(training_set, validation_data=validation_set, epochs=30)

import matplotlib.pyplot as plt
plt.plot(his4.history['accuracy'])
plt.plot(his4.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

